{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictKeys = [\"Temp\",\"Humidity\",\"LightIntensity\",\"CO2Levels\",\"SoundIntensity\",\"BX\",\"BY\",\"BZ\",\"Vibrations\"]\n",
    "NumFeatures = len(dictKeys)\n",
    "dataLen = 1000\n",
    "TrainingData = pd.DataFrame(np.random.randn(len(dictKeys),dataLen)).T\n",
    "TrainingLabels = []\n",
    "for i in range(dataLen):\n",
    "    TrainingLabels.append(random.randint(0,len(dictKeys)))\n",
    "    \n",
    "    \n",
    "TrainingLabels = pd.DataFrame(np.array(TrainingLabels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Netwok Creation using Tensorflow Lazy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BatchSize = 100\n",
    "HiddenLayerNeurons = NumFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataIn = tf.placeholder(tf.float64,[BatchSize,NumFeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrueLabels = tf.placeholder(tf.float64,[BatchSize,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possibleActionsCount = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HL1Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL1Out = tf.sigmoid(tf.matmul(DataIn,HL1Thetas))\n",
    "HL2Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL2Out = tf.sigmoid(tf.matmul(HL1Out,HL2Thetas))\n",
    "HL3Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL3Out = tf.sigmoid(tf.matmul(HL2Out,HL3Thetas))\n",
    "HL4Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL4Out = tf.sigmoid(tf.matmul(HL3Out,HL4Thetas))\n",
    "HL5Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL5Out = tf.sigmoid(tf.matmul(HL4Out,HL5Thetas))\n",
    "HL6Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL6Out = tf.sigmoid(tf.matmul(HL5Out,HL5Thetas))\n",
    "HL7Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL7Out = tf.sigmoid(tf.matmul(HL6Out,HL7Thetas))\n",
    "HL8Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL8Out = tf.sigmoid(tf.matmul(HL7Out,HL8Thetas))\n",
    "HL9Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL9Out = tf.sigmoid(tf.matmul(HL8Out,HL9Thetas))\n",
    "HL10Thetas = tf.Variable(np.random.randn(NumFeatures,HiddenLayerNeurons))\n",
    "HL10Out = tf.sigmoid(tf.matmul(HL9Out,HL10Thetas))\n",
    "OtptThetas = tf.Variable(np.random.randn(NumFeatures,possibleActionsCount))\n",
    "Otpt = tf.sigmoid(tf.matmul(HL10Out,OtptThetas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CostFunction = tf.reduce_mean(tf.square(Otpt - TrueLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.000000001)\n",
    "MinimizeError = optimizer.minimize(CostFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as S:\n",
    "    TotalEpochs = 10000\n",
    "    \n",
    "    S.run(Init)\n",
    "    for i in range(TotalEpochs):\n",
    "        \n",
    "        RandomIndices = np.random.randint(0,len(TrainingData),size = BatchSize)\n",
    "        \n",
    "        Data2Feed = {DataIn:np.array(TrainingData.iloc[RandomIndices]),\n",
    "                    TrueLabels:np.array(TrainingLabels.iloc[RandomIndices]).reshape(100,1)}\n",
    "        \n",
    "        S.run(MinimizeError,feed_dict=Data2Feed)\n",
    "        \n",
    "        \n",
    "        CFErrorInCurrentEpoch = S.run([CostFunction],feed_dict = Data2Feed)\n",
    "        if(i%100==0):\n",
    "            print(\"The CF Error in Epoch: \",i,\" is: \",np.sqrt(CFErrorInCurrentEpoch))\n",
    "            \n",
    "#     HL1ThetasActual = S.run([HL1Thetas])\n",
    "    Thetas = []\n",
    "    Thetas.append(S.run([HL1Thetas]))\n",
    "    Thetas.append(S.run([HL2Thetas]))\n",
    "    Thetas.append(S.run([HL3Thetas]))\n",
    "    Thetas.append(S.run([HL4Thetas]))\n",
    "    Thetas.append(S.run([HL5Thetas]))\n",
    "    Thetas.append(S.run([HL6Thetas]))\n",
    "    Thetas.append(S.run([HL7Thetas]))\n",
    "    Thetas.append(S.run([HL8Thetas]))\n",
    "    Thetas.append(S.run([HL9Thetas]))\n",
    "    Thetas.append(S.run([HL10Thetas]))\n",
    "    Thetas.append(S.run([OtptThetas]))\n",
    "    \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (9,9) into shape (9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-2613cd04554a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTrainedThetas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mThetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mTrainedThetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainedThetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mThetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (9,9) into shape (9)"
     ]
    }
   ],
   "source": [
    "import fs\n",
    "\n",
    "TrainedThetas = []\n",
    "for i in range(len(Thetas)):\n",
    "    TrainedThetas.append(Thetas[i][0])\n",
    "\n",
    "TrainedThetas = np.array(TrainedThetas)\n",
    "\n",
    "for i in range(0,len(Thetas)):\n",
    "    np.savetxt(\"HL1Thetas\", TrainedThetas[i], newline=\" \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Of Layer 11\n",
      "Testing on Feature [6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "============================\n",
      "Output of Layer # 0  =  [[1.         0.99923646 0.99999933 0.99203658 0.99949538 0.70266354\n",
      "  0.99993782 0.99999971 0.999589  ]]\n",
      "Output of Layer # 1  =  [[3.66442012e-06 8.50548271e-08 7.91806157e-08 9.99878323e-01\n",
      "  6.99148442e-03 9.96498051e-01 2.95168206e-10 9.99999993e-01\n",
      "  1.00000000e+00]]\n",
      "Output of Layer # 2  =  [[1.71803214e-18 1.27058251e-08 9.97127653e-01 2.76635159e-04\n",
      "  8.36767319e-03 9.99987817e-01 1.24657071e-04 3.78312368e-05\n",
      "  2.24452213e-10]]\n",
      "Output of Layer # 3  =  [[2.27609868e-13 9.99967228e-01 9.99999803e-01 2.95712844e-15\n",
      "  3.36320487e-05 2.33309561e-13 7.66264275e-07 2.42732784e-02\n",
      "  9.99999997e-01]]\n",
      "Output of Layer # 4  =  [[4.46015287e-08 9.99983898e-01 1.00000000e+00 8.43727827e-03\n",
      "  1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99880054e-01\n",
      "  9.98668110e-01]]\n",
      "Output of Layer # 5  =  [[1.90955527e-04 3.32072596e-09 9.40789481e-01 2.80552270e-01\n",
      "  9.06539219e-13 9.67678450e-01 3.41060943e-07 2.07168219e-04\n",
      "  1.01450154e-04]]\n",
      "Output of Layer # 6  =  [[1.04404756e-03 1.74311602e-07 9.99954356e-01 2.62221800e-04\n",
      "  9.99149809e-01 9.94694345e-01 1.67609208e-14 9.99974124e-01\n",
      "  3.39149722e-03]]\n",
      "Output of Layer # 7  =  [[1.00000000e+00 8.92019630e-22 2.24320167e-02 9.99999979e-01\n",
      "  9.99996963e-01 1.65319812e-04 1.21302152e-06 9.98453894e-01\n",
      "  1.00000000e+00]]\n",
      "Output of Layer # 8  =  [[1.04382948e-08 2.51657526e-01 9.99999514e-01 9.93918347e-01\n",
      "  1.00000000e+00 9.99957671e-01 7.06577765e-04 6.38605270e-06\n",
      "  9.82697373e-01]]\n",
      "Output of Layer # 9  =  [[5.61783423e-01 1.00000000e+00 1.00000000e+00 9.98796378e-01\n",
      "  9.99466632e-01 1.06583273e-18 9.99999876e-01 9.97812957e-01\n",
      "  9.99960956e-01]]\n",
      "Output of Layer # 10  =  [[1.26949011e-04 8.61737605e-01 9.94618453e-01 1.36809609e-05]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# def test(features):\n",
    "#     global Thetas\n",
    "\n",
    "print(\"No Of Layer\",len(Thetas))\n",
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "def test(features):\n",
    "    global Thetas\n",
    "    print(\"Testing on Feature\",features)\n",
    "    print(\"============================\")\n",
    "    for i in range(0,len(Thetas)):\n",
    "        out = (np.array(features))\n",
    "        out = sigmoid(np.dot(out,Thetas[i]))\n",
    "        print(\"Output of Layer #\",i,\" = \",out)\n",
    "    return out\n",
    "\n",
    "        \n",
    "print(test([6]*len(dictKeys)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
